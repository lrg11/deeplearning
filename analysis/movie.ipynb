{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\李蓉\\AppData\\Local\\Temp\\ipykernel_29860\\791884596.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append([[txt,labels[l]]],ignore_index=True)\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
      "1  OK... so... I really like Kris Kristofferson a...          0\n",
      "2  ***SPOILER*** Do not read this, if you think a...          0\n"
     ]
    }
   ],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "labels = {'pos':1,'neg':0}\n",
    "df = pd.DataFrame()\n",
    "for s in ('test','train'):\n",
    "    for l in ('pos','neg'):\n",
    "        path = 'D:/LearnYourself/python/aclImdb_v1/aclImdb/%s/%s' % (s,l)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path,file),'r',encoding='UTF-8') as infile:\n",
    "                txt = infile.read()\n",
    "            df = df.append([[txt,labels[l]]],ignore_index=True)\n",
    "            pbar.update()\n",
    "df.columns = ['review','sentiment']\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('D:/LearnYourself/python/aclImdb_v1/aclImdb/movie_data.csv',index=False)\n",
    "df = pd.read_csv('D:/LearnYourself/python/aclImdb_v1/aclImdb/movie_data.csv')\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11004]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 18-19: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m\n\u001b[0;32m     41\u001b[0m lr_tfidf \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     42\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mvect\u001b[39m\u001b[39m'\u001b[39m,tfidf),\n\u001b[0;32m     43\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m,LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[0;32m     44\u001b[0m ])\n\u001b[0;32m     45\u001b[0m gs_lr_tfidf \u001b[39m=\u001b[39m GridSearchCV(lr_tfidf,param_grid,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m gs_lr_tfidf\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mbest choice\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[39mprint\u001b[39m(gs_lr_tfidf\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:827\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    816\u001b[0m fit_and_score_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m    817\u001b[0m     scorer\u001b[39m=\u001b[39mscorers,\n\u001b[0;32m    818\u001b[0m     fit_params\u001b[39m=\u001b[39mfit_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    825\u001b[0m )\n\u001b[0;32m    826\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 827\u001b[0m \u001b[39mwith\u001b[39;49;00m parallel:\n\u001b[0;32m    828\u001b[0m     all_candidate_params \u001b[39m=\u001b[39;49m []\n\u001b[0;32m    829\u001b[0m     all_out \u001b[39m=\u001b[39;49m []\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\parallel.py:1312\u001b[0m, in \u001b[0;36mParallel.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_managed_backend \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calling \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1312\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_backend()\n\u001b[0;32m   1313\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\parallel.py:1324\u001b[0m, in \u001b[0;36mParallel._initialize_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1324\u001b[0m     n_jobs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mconfigure(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, parallel\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1325\u001b[0m                                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend_args)\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39msupports_timeout:\n\u001b[0;32m   1327\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1328\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mThe backend class \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m does not support timeout. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1329\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou have set \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m in Parallel but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1330\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameter will not be used.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1331\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m,\n\u001b[0;32m   1332\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\_parallel_backends.py:550\u001b[0m, in \u001b[0;36mLokyBackend.configure\u001b[1;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    547\u001b[0m     \u001b[39mraise\u001b[39;00m FallbackToBackend(\n\u001b[0;32m    548\u001b[0m         SequentialBackend(nesting_level\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnesting_level))\n\u001b[1;32m--> 550\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers \u001b[39m=\u001b[39m get_memmapping_executor(\n\u001b[0;32m    551\u001b[0m     n_jobs, timeout\u001b[39m=\u001b[39;49midle_worker_timeout,\n\u001b[0;32m    552\u001b[0m     env\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_worker_env(n_jobs\u001b[39m=\u001b[39;49mn_jobs),\n\u001b[0;32m    553\u001b[0m     context_id\u001b[39m=\u001b[39;49mparallel\u001b[39m.\u001b[39;49m_id, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmemmappingexecutor_args)\n\u001b[0;32m    554\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel \u001b[39m=\u001b[39m parallel\n\u001b[0;32m    555\u001b[0m \u001b[39mreturn\u001b[39;00m n_jobs\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\executor.py:20\u001b[0m, in \u001b[0;36mget_memmapping_executor\u001b[1;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_memmapping_executor\u001b[39m(n_jobs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m MemmappingExecutor\u001b[39m.\u001b[39;49mget_memmapping_executor(n_jobs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\executor.py:42\u001b[0m, in \u001b[0;36mMemmappingExecutor.get_memmapping_executor\u001b[1;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[0;32m     39\u001b[0m reuse \u001b[39m=\u001b[39m _executor_args \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m _executor_args \u001b[39m==\u001b[39m executor_args\n\u001b[0;32m     40\u001b[0m _executor_args \u001b[39m=\u001b[39m executor_args\n\u001b[1;32m---> 42\u001b[0m manager \u001b[39m=\u001b[39m TemporaryResourcesManager(temp_folder)\n\u001b[0;32m     44\u001b[0m \u001b[39m# reducers access the temporary folder in which to store temporary\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# pickles through a call to manager.resolve_temp_folder_name. resolving\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m# the folder name dynamically is useful to use different folders across\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# calls of a same reusable executor\u001b[39;00m\n\u001b[0;32m     48\u001b[0m job_reducers, result_reducers \u001b[39m=\u001b[39m get_memmapping_reducers(\n\u001b[0;32m     49\u001b[0m     unlink_on_gc_collect\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     50\u001b[0m     temp_folder_resolver\u001b[39m=\u001b[39mmanager\u001b[39m.\u001b[39mresolve_temp_folder_name,\n\u001b[0;32m     51\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbackend_args)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:535\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.__init__\u001b[1;34m(self, temp_folder_root, context_id)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[39mif\u001b[39;00m context_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    530\u001b[0m     \u001b[39m# It would be safer to not assign a default context id (less silent\u001b[39;00m\n\u001b[0;32m    531\u001b[0m     \u001b[39m# bugs), but doing this while maintaining backward compatibility\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[39m# with the previous, context-unaware version get_memmaping_executor\u001b[39;00m\n\u001b[0;32m    533\u001b[0m     \u001b[39m# exposes too many low-level details.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m     context_id \u001b[39m=\u001b[39m uuid4()\u001b[39m.\u001b[39mhex\n\u001b[1;32m--> 535\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_current_context(context_id)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:539\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.set_current_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_current_context\u001b[39m(\u001b[39mself\u001b[39m, context_id):\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_context_id \u001b[39m=\u001b[39m context_id\n\u001b[1;32m--> 539\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregister_new_context(context_id)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:564\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.register_new_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    557\u001b[0m new_folder_name \u001b[39m=\u001b[39m (\n\u001b[0;32m    558\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mjoblib_memmapping_folder_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    559\u001b[0m         os\u001b[39m.\u001b[39mgetpid(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id, context_id)\n\u001b[0;32m    560\u001b[0m )\n\u001b[0;32m    561\u001b[0m new_folder_path, _ \u001b[39m=\u001b[39m _get_temp_dir(\n\u001b[0;32m    562\u001b[0m     new_folder_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_temp_folder_root\n\u001b[0;32m    563\u001b[0m )\n\u001b[1;32m--> 564\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregister_folder_finalizer(new_folder_path, context_id)\n\u001b[0;32m    565\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_temp_folders[context_id] \u001b[39m=\u001b[39m new_folder_path\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\_memmapping_reducer.py:580\u001b[0m, in \u001b[0;36mTemporaryResourcesManager.register_folder_finalizer\u001b[1;34m(self, pool_subfolder, context_id)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mregister_folder_finalizer\u001b[39m(\u001b[39mself\u001b[39m, pool_subfolder, context_id):\n\u001b[0;32m    574\u001b[0m     \u001b[39m# Register the garbage collector at program exit in case caller forgets\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[39m# to call terminate explicitly: note we do not pass any reference to\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[39m# ensure that this callback won't prevent garbage collection of\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     \u001b[39m# parallel instance and related file handler resources such as POSIX\u001b[39;00m\n\u001b[0;32m    578\u001b[0m     \u001b[39m# semaphores and pipes\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     pool_module_name \u001b[39m=\u001b[39m whichmodule(delete_folder, \u001b[39m'\u001b[39m\u001b[39mdelete_folder\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 580\u001b[0m     resource_tracker\u001b[39m.\u001b[39;49mregister(pool_subfolder, \u001b[39m\"\u001b[39;49m\u001b[39mfolder\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    582\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_cleanup\u001b[39m():\n\u001b[0;32m    583\u001b[0m         \u001b[39m# In some cases the Python runtime seems to set delete_folder to\u001b[39;00m\n\u001b[0;32m    584\u001b[0m         \u001b[39m# None just before exiting when accessing the delete_folder\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[39m# because joblib should only use relative imports to allow\u001b[39;00m\n\u001b[0;32m    590\u001b[0m         \u001b[39m# easy vendoring.\u001b[39;00m\n\u001b[0;32m    591\u001b[0m         delete_folder \u001b[39m=\u001b[39m \u001b[39m__import__\u001b[39m(\n\u001b[0;32m    592\u001b[0m             pool_module_name, fromlist\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mdelete_folder\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    593\u001b[0m         )\u001b[39m.\u001b[39mdelete_folder\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:179\u001b[0m, in \u001b[0;36mResourceTracker.register\u001b[1;34m(self, name, rtype)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Register a named resource, and increment its refcount.\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mensure_running()\n\u001b[1;32m--> 179\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send(\u001b[39m\"\u001b[39;49m\u001b[39mREGISTER\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, rtype)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py:196\u001b[0m, in \u001b[0;36mResourceTracker._send\u001b[1;34m(self, cmd, name, rtype)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(name) \u001b[39m>\u001b[39m \u001b[39m512\u001b[39m:\n\u001b[0;32m    193\u001b[0m     \u001b[39m# posix guarantees that writes to a pipe of less than PIPE_BUF\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[39m# bytes are atomic, and that PIPE_BUF >= 512\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mname too long\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mcmd\u001b[39m}\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m{\u001b[39;49;00mrtype\u001b[39m}\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mencode(\u001b[39m\"\u001b[39;49m\u001b[39mascii\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    197\u001b[0m nbytes \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mwrite(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fd, msg)\n\u001b[0;32m    198\u001b[0m \u001b[39massert\u001b[39;00m nbytes \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(msg)\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 18-19: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "import pandas as pd\n",
    "df = pd.read_csv('D:/LearnYourself/python/aclImdb_v1/aclImdb/movie_data1.csv')#读出我们放入CSV中的数据\n",
    "\n",
    "import re\n",
    "def delete_html(text):\n",
    "    text = re.sub('<[^>]*>', \" \", text)\n",
    "    emoticion = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text = re.sub('[\\W]+',' ',text.lower())+''.join(emoticion).replace('-','')\n",
    "    return text\n",
    "df['review']= df['review'].apply(delete_html)\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "def stem_tokenizer(text):\n",
    "    porter = PorterStemmer()\n",
    "    return  [porter.stem(word) for word in text.split()]\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "X_train  = df.loc[:1000,'review'].values\n",
    "y_train  = df.loc[:1000,'sentiment'].values\n",
    "X_test  = df.loc[1000:2000,'review'].values\n",
    "y_test  = df.loc[1000:2000,'sentiment'].values\n",
    "\n",
    "from  sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None)\n",
    "param_grid = [{\n",
    "        'vect__ngram_range':[(1,1)],\n",
    "       'vect__stop_words':[stop,None],\n",
    "        'vect__tokenizer':[tokenizer,stem_tokenizer],\n",
    "        'vect__use_idf':[False,True],\n",
    "        'vect__norm':[None,'l1','l2'],\n",
    "        'clf__penalty':['l1','l2'],\n",
    "        'clf__C':[1.0,10.0,100.0]\n",
    "        }]\n",
    "lr_tfidf = Pipeline([\n",
    "    ('vect',tfidf),\n",
    "    ('clf',LogisticRegression(random_state=0))\n",
    "])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf,param_grid,scoring='accuracy',cv=5,verbose=1,n_jobs=-1)\n",
    "gs_lr_tfidf.fit(X_train,y_train)\n",
    "print('best choice')\n",
    "print(gs_lr_tfidf.best_params_)\n",
    "print('Cv score')\n",
    "print(gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'perceptron', 'squared_error', 'epsilon_insensitive', 'log_loss', 'modified_huber', 'squared_epsilon_insensitive', 'hinge', 'huber'}. Got 'log' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     x_train \u001b[39m=\u001b[39m vect\u001b[39m.\u001b[39mtransform(x_train)\n\u001b[1;32m---> 44\u001b[0m     clf\u001b[39m.\u001b[39;49mpartial_fit(x_train,y_train,classes\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marray([\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m]))\n\u001b[0;32m     45\u001b[0m     pb\u001b[39m.\u001b[39mupdate()\n\u001b[0;32m     46\u001b[0m x_test,y_test \u001b[39m=\u001b[39m get_doc(doc_stream,size\u001b[39m=\u001b[39m\u001b[39m5000\u001b[39m)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\sklearn\\base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[0;32m   1140\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1141\u001b[0m )\n\u001b[0;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1144\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[0;32m   1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\sklearn\\base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    630\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    631\u001b[0m \n\u001b[0;32m    632\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[0;32m    639\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    640\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    641\u001b[0m     )\n",
      "File \u001b[1;32md:\\Softwares\\Python3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'perceptron', 'squared_error', 'epsilon_insensitive', 'log_loss', 'modified_huber', 'squared_epsilon_insensitive', 'hinge', 'huber'}. Got 'log' instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "import re\n",
    "def delete_html(text):\n",
    "    text = re.sub('<[^>]*>', \" \", text)\n",
    "    emoticion = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text = re.sub('[\\W]+',' ',text.lower())+''.join(emoticion).replace('-','')\n",
    "    token = [w for w in text.split() if w not in stop]\n",
    "    return token\n",
    "\n",
    "def stream_doc(path):\n",
    "    with open(path,'r', encoding='UTF-8') as csv:\n",
    "        next(csv)\n",
    "        for line in csv:\n",
    "            text,lable = line[:-3],int(line[-2])\n",
    "            yield text,lable\n",
    "\n",
    "def get_doc(doc_stream,size):\n",
    "    doc,y = [],[]\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text,lable = next(doc_stream)\n",
    "            doc.append(text)\n",
    "            y.append(lable)\n",
    "    except StopIteration:\n",
    "        return None,None\n",
    "    return doc,y\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "vect = HashingVectorizer(decode_error='ignore',n_features=2**21,preprocessor=None,tokenizer=delete_html)\n",
    "clf = SGDClassifier(loss='log',random_state=1,n_iter_no_change=1)\n",
    "doc_stream = stream_doc(path='D:/LearnYourself/python/aclImdb_v1/aclImdb/movie_data.csv')\n",
    "\n",
    "import pyprind\n",
    "pb = pyprind.ProgBar(45)\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    x_train,y_train = get_doc(doc_stream,size=1000)\n",
    "    if not x_train:\n",
    "        break\n",
    "    x_train = vect.transform(x_train)\n",
    "    clf.partial_fit(x_train,y_train,classes=np.array([0, 1]))\n",
    "    pb.update()\n",
    "x_test,y_test = get_doc(doc_stream,size=5000)\n",
    "print(x_test)\n",
    "x_test = vect.transform(x_test)\n",
    "print(clf.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
